# main.py
import time
import threading
import numpy as np
import whisper
import sounddevice as sd
from queue import Queue
from rich.console import Console
from rich.panel import Panel
from rich.text import Text
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain.prompts import PromptTemplate
from langchain_community.llms import Ollama
from tts import TextToSpeechService
from config import Config
from real_web_search import RealWebSearchService
from conversation_logger import ConversationLogger
from audio_processor import EnhancedAudioProcessor
from enhanced_ai import EnhancedAIAssistant

console = Console()
stt = whisper.load_model(Config.WHISPER_MODEL)
tts = TextToSpeechService()
web_search = RealWebSearchService()
logger = ConversationLogger()
audio_processor = EnhancedAudioProcessor()
enhanced_ai = EnhancedAIAssistant(Config)

# Enhanced prompt template with personality - Thai language (Professional Version)
template = """
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ Heckx ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡∏ü‡∏µ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏±‡∏• ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏î‡∏¢ bobo ‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÉ‡∏ô‡∏Å‡∏≤‡∏£:

üéØ ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏•‡∏∞‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢
üñºÔ∏è ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏•‡∏∂‡∏Å‡∏ã‡∏∂‡πâ‡∏á
üìö ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢
üé≠ ‡∏°‡∏µ‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏±‡∏ô
üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡πÑ‡∏î‡πâ

‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
- ‡∏ï‡∏≠‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏™‡∏°‡∏≠
- ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û
- ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
- ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö: 50-500 ‡∏Ñ‡∏≥ (‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°)
- ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå/‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡πÄ‡∏ó‡πá‡∏à‡∏à‡∏£‡∏¥‡∏á: ‡πÉ‡∏´‡πâ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô

‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ß‡πá‡∏ö ‡πÉ‡∏´‡πâ‡∏ô‡∏≥‡∏°‡∏≤‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö

‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤:
{history}

‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤: {input}

‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û):
"""
PROMPT = PromptTemplate(input_variables=["history", "input"], template=template)
chain = ConversationChain(
    prompt=PROMPT,
    verbose=False,
    memory=ConversationBufferMemory(
        ai_prefix="Heckx:",
        human_prefix="You:",
        k=Config.CONVERSATION_HISTORY_LIMIT
    ),
    llm=Ollama(model=Config.OLLAMA_MODEL),
)

class VoiceAssistant:
    def __init__(self):
        self.console = console
        self.data_queue = Queue()
        self.stop_event = threading.Event()
        self.is_recording = False
        self.session_id = logger.start_session("Voice mode session")

    def record_audio(self):
        """Captures audio and puts it in the queue."""
        def callback(indata, frames, time, status):
            if status:
                self.console.print(f"[red]Audio Error: {status}")
            if self.is_recording:
                audio_level = np.abs(indata).mean()
                if audio_level > Config.AUDIO_THRESHOLD:
                    self.data_queue.put(bytes(indata))

        with sd.RawInputStream(
            samplerate=Config.SAMPLE_RATE,
            dtype=Config.DTYPE,
            channels=Config.CHANNELS,
            callback=callback
        ):
            while not self.stop_event.is_set():
                time.sleep(0.1)

    def transcribe(self, audio_np: np.ndarray) -> str:
        """Transcribes audio to text."""
        result = stt.transcribe(audio_np, fp16=False)
        text = result["text"].strip()
        return text

    def get_response(self, text: str) -> str:
        """Gets enhanced response with context awareness."""
        start_time = time.time()
        
        try:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            web_info = ""
            if web_search.should_search_web(text):
                print("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î...")
                search_results = web_search.search_real_time(text)
                web_info = web_search.format_search_results(search_results, text)
            
            # ‡πÉ‡∏ä‡πâ Enhanced AI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö
            response = enhanced_ai.get_enhanced_response(text, web_info)
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
            response_time = time.time() - start_time
            logger.log_conversation(
                user_input=text,
                ai_response=response,
                response_time=response_time,
                mode="voice",
                metadata={
                    'web_search_used': bool(web_info),
                    'enhanced_ai_used': True,
                    'response_time': response_time
                }
            )
            
            return response
            
        except Exception as e:
            print(f"Error in get_response: {e}")
            return f"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"

    def play_audio(self, sample_rate: int, audio_array: np.ndarray):
        """Plays audio array."""
        sd.play(audio_array, sample_rate)
        sd.wait()

    def display_welcome(self):
        """Displays welcome message."""
        welcome_text = Text.assemble(
            ("‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á!\n", "cyan bold"),
            ("‡∏Å‡∏î Enter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏û‡∏π‡∏î, ‡∏Å‡∏î Enter ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î\n", "white"),
            ("‡∏Å‡∏î Ctrl+C ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å ‡∏°‡∏≤‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ô‡πÄ‡∏ñ‡∏≠‡∏∞!", "cyan")
        )
        self.console.print(Panel(welcome_text, title="Heckx", border_style="blue"))

    def run(self):
        """Main loop for the assistant with enhanced audio."""
        self.display_welcome()
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Å‡πà‡∏≠‡∏ô
        if not audio_processor.test_audio_system():
            self.console.print(Panel(
                "‚ö†Ô∏è  ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô",
                title="‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô",
                border_style="yellow"
            ))
        
        try:
            while True:
                self.console.input(
                    "[green]‡∏Å‡∏î Enter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏û‡∏π‡∏î (‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ü‡∏±‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)...[/green]"
                )
                
                # ‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞
                with self.console.status("[blue]üé§ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ü‡∏±‡∏á... (‡∏û‡∏π‡∏î‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)", spinner="dots"):
                    audio_data = audio_processor.smart_recording(duration_limit=30.0)

                if audio_data.size > 0:
                    with self.console.status("[blue]üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á...", spinner="dots"):
                        text = audio_processor.transcribe_with_whisper(audio_data, stt)
                    
                    if text.strip():
                        self.console.print(Panel(
                            f"‡∏Ñ‡∏∏‡∏ì: {text}",
                            title="‚úÖ ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏û‡∏π‡∏î",
                            border_style="yellow"
                        ))

                        with self.console.status("[blue]ü§î ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î...", spinner="moon"):
                            response = self.get_response(text)
                            sample_rate, audio_array = tts.long_form_synthesize(response)

                        self.console.print(Panel(
                            f"Heckx: {response}",
                            title="ü§ñ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á Heckx",
                            border_style="cyan"
                        ))
                        
                        self.play_audio(sample_rate, audio_array)
                    else:
                        self.console.print(Panel(
                            "‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà",
                            title="‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î",
                            border_style="red"
                        ))
                else:
                    self.console.print(Panel(
                        "üîá ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà",
                        title="‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á",
                        border_style="yellow"
                    ))

        except KeyboardInterrupt:
            self.console.print("\n[red]üõë ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏¥‡∏î‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢...")
            logger.end_session()
            self.console.print(Panel(
                "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏¢‡∏î‡πâ‡∏ß‡∏¢! ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏ô‡∏∞! üëã",
                title="‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô",
                border_style="blue"
            ))

if __name__ == "__main__":
    assistant = VoiceAssistant()
    assistant.run()